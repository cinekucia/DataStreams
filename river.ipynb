{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CtNAW1zHR2ro"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import collections\n",
        "import itertools\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from river import base\n",
        "from river.drift import ADWIN\n",
        "from river.metrics import Accuracy\n",
        "from river.tree import HoeffdingTreeClassifier\n",
        "from river.utils.random import poisson\n",
        "\n",
        "# Utility to generate a random feature subspace.\n",
        "def random_subspace(all_features: list, k: int, rng: random.Random):\n",
        "    return rng.sample(all_features, k=k)\n",
        "\n",
        "###############################################################################\n",
        "# Base Ensemble and Estimator Classes\n",
        "###############################################################################\n",
        "\n",
        "class BaseSRPEnsemble(base.Wrapper, base.Ensemble):\n",
        "    _TRAIN_RANDOM_SUBSPACES = \"subspaces\"\n",
        "    _TRAIN_RESAMPLING = \"resampling\"\n",
        "    _TRAIN_RANDOM_PATCHES = \"patches\"\n",
        "\n",
        "    _FEATURES_SQRT = \"sqrt\"\n",
        "    _FEATURES_SQRT_INV = \"rmsqrt\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: base.Estimator | None = None,\n",
        "        n_models: int = 10,\n",
        "        subspace_size: int | float | str = 0.6,\n",
        "        training_method: str = \"patches\",\n",
        "        lam: float = 6.0,\n",
        "        drift_detector: base.DriftDetector | None = None,\n",
        "        warning_detector: base.DriftDetector | None = None,\n",
        "        disable_weighted_vote: bool = False,\n",
        "        disable_detector: str = \"off\",\n",
        "        seed: int | None = None,\n",
        "        metric: Accuracy | None = None,\n",
        "    ):\n",
        "        super().__init__([])  # start with an empty ensemble\n",
        "        self.model = model\n",
        "        self.n_models = n_models\n",
        "        self.subspace_size = subspace_size\n",
        "        self.training_method = training_method\n",
        "        self.lam = lam\n",
        "        self.drift_detector = drift_detector if drift_detector is not None else ADWIN(delta=1e-5)\n",
        "        self.warning_detector = warning_detector if warning_detector is not None else ADWIN(delta=1e-4)\n",
        "        self.disable_weighted_vote = disable_weighted_vote\n",
        "        self.disable_detector = disable_detector\n",
        "        self.metric = metric if metric is not None else Accuracy()\n",
        "        self.seed = seed\n",
        "        self._rng = random.Random(self.seed)\n",
        "        self._n_samples_seen = 0\n",
        "        self._subspaces: list = []\n",
        "        # This attribute must be set by the subclass.\n",
        "        self._base_learner_class = None\n",
        "\n",
        "    def _init_ensemble(self, features: list):\n",
        "        self._generate_subspaces(features)\n",
        "        subspace_indexes = list(range(self.n_models))\n",
        "        if self.training_method in {self._TRAIN_RANDOM_PATCHES, self._TRAIN_RANDOM_SUBSPACES}:\n",
        "            self._rng.shuffle(subspace_indexes)\n",
        "        for i in range(self.n_models):\n",
        "            subspace = self._subspaces[subspace_indexes[i]]\n",
        "            self.append(\n",
        "                self._base_learner_class(\n",
        "                    idx_original=i,\n",
        "                    model=self.model,\n",
        "                    metric=self.metric,\n",
        "                    created_on=self._n_samples_seen,\n",
        "                    drift_detector=self.drift_detector,\n",
        "                    warning_detector=self.warning_detector,\n",
        "                    is_background_learner=False,\n",
        "                    rng=self._rng,\n",
        "                    features=subspace,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def _generate_subspaces(self, features: list):\n",
        "        n_features = len(features)\n",
        "        # If we're not doing resampling, we try to compute a subspace\n",
        "        if self.training_method != self._TRAIN_RESAMPLING:\n",
        "            if isinstance(self.subspace_size, float) and 0.0 < self.subspace_size <= 1:\n",
        "                k = self.subspace_size\n",
        "                percent = (1.0 + k)\n",
        "                k = round(n_features * percent)\n",
        "                if k < 2:\n",
        "                    k = round(n_features * percent) + 1\n",
        "            elif isinstance(self.subspace_size, int) and self.subspace_size > 2:\n",
        "                k = self.subspace_size\n",
        "            elif self.subspace_size == self._FEATURES_SQRT:\n",
        "                k = round(math.sqrt(n_features)) + 1\n",
        "            elif self.subspace_size == self._FEATURES_SQRT_INV:\n",
        "                k = n_features - round(math.sqrt(n_features)) + 1\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid subspace_size: {self.subspace_size}.\")\n",
        "            if k < 0:\n",
        "                k = n_features + k\n",
        "            if k != 0 and k < n_features:\n",
        "                if n_features <= 20 or k < 2:\n",
        "                    if k == 1 and n_features > 2:\n",
        "                        k = 2\n",
        "                    self._subspaces = []\n",
        "                    for i, combination in enumerate(\n",
        "                        itertools.cycle(itertools.combinations(features, k))\n",
        "                    ):\n",
        "                        if i == self.n_models:\n",
        "                            break\n",
        "                        self._subspaces.append(list(combination))\n",
        "                else:\n",
        "                    self._subspaces = [\n",
        "                        random_subspace(all_features=features, k=k, rng=self._rng)\n",
        "                        for _ in range(self.n_models)\n",
        "                    ]\n",
        "            else:\n",
        "                # When k is not less than the number of features, switch to resampling\n",
        "                self.training_method = self._TRAIN_RESAMPLING\n",
        "                self._subspaces = [None] * self.n_models\n",
        "        else:\n",
        "            self._subspaces = [None] * self.n_models\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = []\n",
        "        self._n_samples_seen = 0\n",
        "        self._rng = random.Random(self.seed)\n",
        "\n",
        "class BaseSRPEstimator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        idx_original: int,\n",
        "        model: base.Estimator,\n",
        "        metric: Accuracy,\n",
        "        created_on: int,\n",
        "        drift_detector: base.DriftDetector,\n",
        "        warning_detector: base.DriftDetector,\n",
        "        is_background_learner,\n",
        "        rng: random.Random,\n",
        "        features=None,\n",
        "    ):\n",
        "        self.idx_original = idx_original\n",
        "        self.created_on = created_on\n",
        "        self.model = model.clone()\n",
        "        self.metric = metric.clone()\n",
        "        self.features = features\n",
        "        if drift_detector is not None:\n",
        "            self.disable_drift_detector = False\n",
        "            self.drift_detector = drift_detector.clone()\n",
        "        else:\n",
        "            self.disable_drift_detector = True\n",
        "            self.drift_detector = None\n",
        "        if warning_detector is not None:\n",
        "            self.disable_background_learner = False\n",
        "            self.warning_detector = warning_detector.clone()\n",
        "        else:\n",
        "            self.disable_background_learner = True\n",
        "            self.warning_detector = None\n",
        "        self.is_background_learner = is_background_learner\n",
        "        self.n_drifts_detected = 0\n",
        "        self.n_warnings_detected = 0\n",
        "        self.rng = rng\n",
        "        self._background_learner = None\n",
        "\n",
        "###############################################################################\n",
        "# Base Learner for Classification with Weighting\n",
        "###############################################################################\n",
        "\n",
        "class BaseSRPClassifier(BaseSRPEstimator):\n",
        "    def __init__(\n",
        "        self,\n",
        "        idx_original: int,\n",
        "        model: base.Classifier,\n",
        "        metric: Accuracy,\n",
        "        created_on: int,\n",
        "        drift_detector: base.DriftDetector,\n",
        "        warning_detector: base.DriftDetector,\n",
        "        is_background_learner,\n",
        "        rng: random.Random,\n",
        "        features=None,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            idx_original, model, metric, created_on, drift_detector, warning_detector, is_background_learner, rng, features\n",
        "        )\n",
        "        self.weight = 1.0  # initialize the base learner's weight\n",
        "\n",
        "    def reset(self, all_features: list, n_samples_seen: int):\n",
        "        # Optionally, update the feature subspace using a new random sample\n",
        "        if self.features is not None:\n",
        "            self.features = random_subspace(all_features, len(self.features), self.rng)\n",
        "        # Reset the underlying model and metrics\n",
        "        self.model = self.model.clone()\n",
        "        self.metric = self.metric.clone()\n",
        "        self.created_on = n_samples_seen\n",
        "        if self.drift_detector is not None:\n",
        "            self.drift_detector = self.drift_detector.clone()\n",
        "        if self.warning_detector is not None:\n",
        "            self.warning_detector = self.warning_detector.clone()\n",
        "        self.weight = 1.0\n",
        "\n",
        "    def learn_one(self, x: dict, y: base.typing.ClfTarget, *, w: int, n_samples_seen: int, **kwargs):\n",
        "        if self.features is not None:\n",
        "            x_subset = {k: x[k] for k in self.features if k in x}\n",
        "        else:\n",
        "            x_subset = x\n",
        "        for _ in range(int(w)):\n",
        "            self.model.learn_one(x=x_subset, y=y, **kwargs)\n",
        "        if self._background_learner:\n",
        "            self._background_learner.learn_one(x=x, y=y, w=w, n_samples_seen=n_samples_seen)\n",
        "        if not self.disable_drift_detector and not self.is_background_learner:\n",
        "            y_pred = self.model.predict_one(x_subset)\n",
        "            correctly_classifies = (y_pred == y)\n",
        "            # Update the learner's weight: decrease if correct, increase if wrong\n",
        "            if correctly_classifies:\n",
        "                self.weight *= 0.9\n",
        "            else:\n",
        "                self.weight *= 1.1\n",
        "            self.warning_detector.update(int(not correctly_classifies))\n",
        "            if self.warning_detector.drift_detected:\n",
        "                all_features = list(x.keys())\n",
        "                self.n_warnings_detected += 1\n",
        "                # (Optional: trigger background learning here)\n",
        "            self.drift_detector.update(int(not correctly_classifies))\n",
        "            if self.drift_detector.drift_detected:\n",
        "                all_features = list(x.keys())\n",
        "                self.n_drifts_detected += 1\n",
        "                # Call the newly added reset method\n",
        "                self.reset(all_features=all_features, n_samples_seen=n_samples_seen)\n",
        "\n",
        "    def predict_proba_one(self, x, **kwargs):\n",
        "        if self.features is not None:\n",
        "            x_subset = {k: x[k] for k in self.features if k in x}\n",
        "        else:\n",
        "            x_subset = x\n",
        "        return self.model.predict_proba_one(x_subset, **kwargs)\n",
        "\n",
        "    def predict_one(self, x: dict, **kwargs) -> base.typing.ClfTarget:\n",
        "        y_pred = self.predict_proba_one(x, **kwargs)\n",
        "        if y_pred:\n",
        "            return max(y_pred, key=y_pred.get)\n",
        "        return None\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Standard SRPClassifier (for reference)\n",
        "###############################################################################\n",
        "\n",
        "class SRPClassifier(BaseSRPEnsemble, base.Classifier):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: base.Estimator | None = None,\n",
        "        n_models: int = 10,\n",
        "        subspace_size: int | float | str = 0.6,\n",
        "        training_method: str = \"patches\",\n",
        "        lam: int = 6,\n",
        "        drift_detector: base.DriftDetector | None = None,\n",
        "        warning_detector: base.DriftDetector | None = None,\n",
        "        disable_detector: str = \"off\",\n",
        "        disable_weighted_vote: bool = False,\n",
        "        seed: int | None = None,\n",
        "        metric: Accuracy | None = None,\n",
        "    ):\n",
        "        if model is None:\n",
        "            model = HoeffdingTreeClassifier(grace_period=50, delta=0.01)\n",
        "        if drift_detector is None:\n",
        "            drift_detector = ADWIN(delta=1e-5)\n",
        "        if warning_detector is None:\n",
        "            warning_detector = ADWIN(delta=1e-4)\n",
        "        if metric is None:\n",
        "            metric = Accuracy()\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            n_models=n_models,\n",
        "            subspace_size=subspace_size,\n",
        "            training_method=training_method,\n",
        "            lam=lam,\n",
        "            drift_detector=drift_detector,\n",
        "            warning_detector=warning_detector,\n",
        "            disable_detector=disable_detector,\n",
        "            disable_weighted_vote=disable_weighted_vote,\n",
        "            seed=seed,\n",
        "            metric=metric,\n",
        "        )\n",
        "        self._base_learner_class = BaseSRPClassifier\n",
        "\n",
        "    def predict_proba_one(self, x, **kwargs):\n",
        "        y_pred = collections.Counter()\n",
        "        if not self:\n",
        "            self._init_ensemble(features=list(x.keys()))\n",
        "            return y_pred\n",
        "        for model in self:\n",
        "            y_proba_temp = model.predict_proba_one(x, **kwargs)\n",
        "            if not self.disable_weighted_vote:\n",
        "                # Use the learner's weight for vote weighting\n",
        "                weight = model.weight\n",
        "                y_proba_temp = {k: val * weight for k, val in y_proba_temp.items()}\n",
        "            y_pred.update(y_proba_temp)\n",
        "        total = sum(y_pred.values())\n",
        "        if total > 0:\n",
        "            return {label: proba / total for label, proba in y_pred.items()}\n",
        "        return y_pred\n",
        "\n",
        "    def predict_one(self, x, **kwargs):\n",
        "        y_pred = self.predict_proba_one(x, **kwargs)\n",
        "        if y_pred:\n",
        "            return max(y_pred, key=y_pred.get)\n",
        "        return None\n",
        "\n",
        "###############################################################################\n",
        "# Dynamic SRPClassifier: Adaptive Ensemble Size\n",
        "###############################################################################\n",
        "\n",
        "class DynamicSRPClassifier(SRPClassifier):\n",
        "    @property\n",
        "    def _min_number_of_models(self):\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def _wrapped_model(self):\n",
        "        return self.model\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: base.Estimator | None = None,\n",
        "        n_models: int = 10,\n",
        "        max_models: int = 100,\n",
        "        subspace_size: int | float | str = 0.6,\n",
        "        training_method: str = \"patches\",\n",
        "        lam: int = 6,\n",
        "        drift_detector: base.DriftDetector | None = None,\n",
        "        warning_detector: base.DriftDetector | None = None,\n",
        "        disable_detector: str = \"off\",\n",
        "        disable_weighted_vote: bool = False,\n",
        "        seed: int | None = None,\n",
        "        metric: Accuracy | None = None,\n",
        "        window_size: int = 100,\n",
        "        performance_threshold: float = 0.8,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            n_models=n_models,\n",
        "            subspace_size=subspace_size,\n",
        "            training_method=training_method,\n",
        "            lam=lam,\n",
        "            drift_detector=drift_detector,\n",
        "            warning_detector=warning_detector,\n",
        "            disable_detector=disable_detector,\n",
        "            disable_weighted_vote=disable_weighted_vote,\n",
        "            seed=seed,\n",
        "            metric=metric,\n",
        "        )\n",
        "        self._max_models = max_models\n",
        "        self._window_size = window_size\n",
        "        self._performance_threshold = performance_threshold\n",
        "        self._sliding_window = collections.deque(maxlen=window_size)\n",
        "\n",
        "    def learn_one(self, x: dict, y: base.typing.ClfTarget, **kwargs):\n",
        "        self._n_samples_seen += 1\n",
        "        if not self:\n",
        "            self._init_ensemble(features=list(x.keys()))\n",
        "        for model in self:\n",
        "            y_pred = model.predict_one(x)\n",
        "            if y_pred is not None:\n",
        "                model.metric.update(y_true=y, y_pred=y_pred)\n",
        "            if self.training_method == self._TRAIN_RANDOM_SUBSPACES:\n",
        "                k = 1\n",
        "            else:\n",
        "                k = poisson(rate=self.lam, rng=self._rng)\n",
        "                if k == 0:\n",
        "                    continue\n",
        "            model.learn_one(x=x, y=y, w=k, n_samples_seen=self._n_samples_seen, **kwargs)\n",
        "        ensemble_pred = self.predict_one(x)\n",
        "        correct = 1 if ensemble_pred == y else 0\n",
        "        self._sliding_window.append(correct)\n",
        "        if len(self._sliding_window) == self._window_size:\n",
        "            window_accuracy = sum(self._sliding_window) / self._window_size\n",
        "            if window_accuracy < self._performance_threshold:\n",
        "                features = list(x.keys())\n",
        "                if len(self) < self._max_models:\n",
        "                    self._add_learner(features)\n",
        "                else:\n",
        "                    self._remove_worst_learner()\n",
        "                    self._add_learner(features)\n",
        "                self._sliding_window.clear()\n",
        "\n",
        "    def _generate_subspace_single(self, features: list):\n",
        "        n_features = len(features)\n",
        "        if self.training_method != self._TRAIN_RESAMPLING:\n",
        "            if isinstance(self.subspace_size, float) and 0.0 < self.subspace_size <= 1:\n",
        "                k = self.subspace_size\n",
        "                percent = (1.0 + k)\n",
        "                k = round(n_features * percent)\n",
        "                if k < 2:\n",
        "                    k = round(n_features * percent) + 1\n",
        "            elif isinstance(self.subspace_size, int) and self.subspace_size > 2:\n",
        "                k = self.subspace_size\n",
        "            elif self.subspace_size == self._FEATURES_SQRT:\n",
        "                k = round(math.sqrt(n_features)) + 1\n",
        "            elif self.subspace_size == self._FEATURES_SQRT_INV:\n",
        "                k = n_features - round(math.sqrt(n_features)) + 1\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid subspace_size: {self.subspace_size}.\")\n",
        "            if k < 0:\n",
        "                k = n_features + k\n",
        "            if k != 0 and k < n_features:\n",
        "                return random_subspace(all_features=features, k=k, rng=self._rng)\n",
        "            else:\n",
        "                self.training_method = self._TRAIN_RESAMPLING\n",
        "                return None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def _add_learner(self, features: list):\n",
        "        subspace = self._generate_subspace_single(features)\n",
        "        new_learner = self._base_learner_class(\n",
        "            idx_original=len(self),\n",
        "            model=self.model,\n",
        "            metric=self.metric.clone(),\n",
        "            created_on=self._n_samples_seen,\n",
        "            drift_detector=self.drift_detector,\n",
        "            warning_detector=self.warning_detector,\n",
        "            is_background_learner=False,\n",
        "            rng=self._rng,\n",
        "            features=subspace,\n",
        "        )\n",
        "        new_learner.weight = 1.0\n",
        "        self.append(new_learner)\n",
        "\n",
        "    def _remove_worst_learner(self):\n",
        "        worst_index = None\n",
        "        worst_weight = float('inf')\n",
        "        for i, learner in enumerate(self):\n",
        "            if learner.weight < worst_weight:\n",
        "                worst_weight = learner.weight\n",
        "                worst_index = i\n",
        "        if worst_index is not None:\n",
        "            del self[worst_index]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from river.datasets import synth\n",
        "dataset = synth.Agrawal( classification_function=0,seed=42).take(10000)\n"
      ],
      "metadata": {
        "id": "yGRkiFMekI6U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from river import ensemble, evaluate, metrics, datasets, tree\n",
        "\n",
        "# Create a synthetic concept drift stream\n",
        "dataset = datasets.synth.ConceptDriftStream(\n",
        "    seed=42,\n",
        "    position=500,\n",
        "    width=50\n",
        ").take(1000)\n",
        "\n",
        "# Define a base model (Hoeffding Tree)\n",
        "base_model = tree.HoeffdingTreeClassifier(\n",
        "    grace_period=50, delta=0.01,\n",
        "    nominal_attributes=['age', 'car', 'zipcode']\n",
        ")\n",
        "\n",
        "\n",
        "# Reinitialize the stream for a fair comparison\n",
        "dataset = datasets.synth.ConceptDriftStream(\n",
        "    seed=42,\n",
        "    position=500,\n",
        "    width=50\n",
        ").take(1000)\n",
        "\n",
        "# --- Dynamic SRPClassifier ---\n",
        "dynamic_model = DynamicSRPClassifier(\n",
        "    model=base_model,\n",
        "    n_models=10,        # starting with 10 learners\n",
        "    max_models=100,     # ensemble will grow up to 100 learners\n",
        "    seed=42,\n",
        "    window_size=100,           # sliding window size for performance monitoring\n",
        "    performance_threshold=0.8  # if accuracy over window falls below 80%, add a learner\n",
        ")\n",
        "\n",
        "result_dynamic = evaluate.progressive_val_score(dataset, dynamic_model, metric)\n",
        "print(\"Dynamic SRPClassifier Accuracy:\", result_dynamic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWZQ1bV9gAiA",
        "outputId": "fb132d7a-c4a3-44ac-949f-b4cfbe1e8302"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dynamic SRPClassifier Accuracy: Accuracy: 74.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from river import ensemble, evaluate, metrics, datasets, tree\n",
        "\n",
        "# Create a synthetic concept drift stream\n",
        "dataset = datasets.synth.ConceptDriftStream(\n",
        "    seed=42,\n",
        "    position=500,\n",
        "    width=50\n",
        ").take(10000)\n",
        "\n",
        "# Define a base model (Hoeffding Tree)\n",
        "base_model = tree.HoeffdingTreeClassifier(\n",
        "    grace_period=50, delta=0.01,\n",
        "    nominal_attributes=['age', 'car', 'zipcode']\n",
        ")\n",
        "\n",
        "# --- Original SRPClassifier ---\n",
        "original_model = ensemble.SRPClassifier(\n",
        "    model=base_model,\n",
        "    n_models=10,  # e.g., 3 base learners\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "metric = metrics.Accuracy()\n",
        "\n",
        "result_original = evaluate.progressive_val_score(dataset, original_model, metric)\n",
        "print(\"Original SRPClassifier Accuracy:\", result_original)\n",
        "\n",
        "# Reinitialize the stream for a fair comparison\n",
        "dataset = datasets.synth.ConceptDriftStream(\n",
        "    seed=42,\n",
        "    position=500,\n",
        "    width=50\n",
        ").take(10000)\n",
        "\n",
        "# --- Dynamic SRPClassifier ---\n",
        "dynamic_model = DynamicSRPClassifier(\n",
        "    model=base_model,\n",
        "    n_models=10,        # starting with 10 learners\n",
        "    max_models=100,     # ensemble will grow up to 100 learners\n",
        "    seed=42,\n",
        "    window_size=100,           # sliding window size for performance monitoring\n",
        "    performance_threshold=0.8  # if accuracy over window falls below 80%, add a learner\n",
        ")\n",
        "\n",
        "result_dynamic = evaluate.progressive_val_score(dataset, dynamic_model, metric)\n",
        "print(\"Dynamic SRPClassifier Accuracy:\", result_dynamic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPzml41KkruS",
        "outputId": "f7e0c502-0d27-49b3-d085-317d4b4b1b81"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original SRPClassifier Accuracy: Accuracy: 68.68%\n",
            "Dynamic SRPClassifier Accuracy: Accuracy: 60.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here look kind gentelman"
      ],
      "metadata": {
        "id": "szUS3CpXnGFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import collections\n",
        "import itertools\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from river import base\n",
        "from river.drift import ADWIN\n",
        "from river.metrics import Accuracy\n",
        "from river.tree import HoeffdingTreeClassifier\n",
        "from river.utils.random import poisson\n",
        "\n",
        "# Utility to generate a random feature subspace.\n",
        "def random_subspace(all_features: list, k: int, rng: random.Random):\n",
        "    return rng.sample(all_features, k=k)\n",
        "\n",
        "###############################################################################\n",
        "# Base Ensemble and Estimator Classes (unchanged)\n",
        "###############################################################################\n",
        "\n",
        "class BaseSRPEnsemble(base.Wrapper, base.Ensemble):\n",
        "    _TRAIN_RANDOM_SUBSPACES = \"subspaces\"\n",
        "    _TRAIN_RESAMPLING = \"resampling\"\n",
        "    _TRAIN_RANDOM_PATCHES = \"patches\"\n",
        "\n",
        "    _FEATURES_SQRT = \"sqrt\"\n",
        "    _FEATURES_SQRT_INV = \"rmsqrt\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: base.Estimator | None = None,\n",
        "        n_models: int = 10,\n",
        "        subspace_size: int | float | str = 0.6,\n",
        "        training_method: str = \"patches\",\n",
        "        lam: float = 6.0,\n",
        "        drift_detector: base.DriftDetector | None = None,\n",
        "        warning_detector: base.DriftDetector | None = None,\n",
        "        disable_weighted_vote: bool = False,\n",
        "        disable_detector: str = \"off\",\n",
        "        seed: int | None = None,\n",
        "        metric: Accuracy | None = None,\n",
        "    ):\n",
        "        super().__init__([])  # start with an empty ensemble\n",
        "        self.model = model\n",
        "        self.n_models = n_models\n",
        "        self.subspace_size = subspace_size\n",
        "        self.training_method = training_method\n",
        "        self.lam = lam\n",
        "        self.drift_detector = drift_detector if drift_detector is not None else ADWIN(delta=1e-5)\n",
        "        self.warning_detector = warning_detector if warning_detector is not None else ADWIN(delta=1e-4)\n",
        "        self.disable_weighted_vote = disable_weighted_vote\n",
        "        self.disable_detector = disable_detector\n",
        "        self.metric = metric if metric is not None else Accuracy()\n",
        "        self.seed = seed\n",
        "        self._rng = random.Random(self.seed)\n",
        "        self._n_samples_seen = 0\n",
        "        self._subspaces: list = []\n",
        "        # This attribute must be set by the subclass.\n",
        "        self._base_learner_class = None\n",
        "\n",
        "    def _init_ensemble(self, features: list):\n",
        "        self._generate_subspaces(features)\n",
        "        subspace_indexes = list(range(self.n_models))\n",
        "        if self.training_method in {self._TRAIN_RANDOM_PATCHES, self._TRAIN_RANDOM_SUBSPACES}:\n",
        "            self._rng.shuffle(subspace_indexes)\n",
        "        for i in range(self.n_models):\n",
        "            subspace = self._subspaces[subspace_indexes[i]]\n",
        "            self.append(\n",
        "                self._base_learner_class(\n",
        "                    idx_original=i,\n",
        "                    model=self.model,\n",
        "                    metric=self.metric,\n",
        "                    created_on=self._n_samples_seen,\n",
        "                    drift_detector=self.drift_detector,\n",
        "                    warning_detector=self.warning_detector,\n",
        "                    is_background_learner=False,\n",
        "                    rng=self._rng,\n",
        "                    features=subspace,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def _generate_subspaces(self, features: list):\n",
        "        n_features = len(features)\n",
        "        # If we're not doing resampling, try to compute a subspace.\n",
        "        if self.training_method != self._TRAIN_RESAMPLING:\n",
        "            if isinstance(self.subspace_size, float) and 0.0 < self.subspace_size <= 1:\n",
        "                k = self.subspace_size\n",
        "                percent = (1.0 + k)\n",
        "                k = round(n_features * percent)\n",
        "                if k < 2:\n",
        "                    k = round(n_features * percent) + 1\n",
        "            elif isinstance(self.subspace_size, int) and self.subspace_size > 2:\n",
        "                k = self.subspace_size\n",
        "            elif self.subspace_size == self._FEATURES_SQRT:\n",
        "                k = round(math.sqrt(n_features)) + 1\n",
        "            elif self.subspace_size == self._FEATURES_SQRT_INV:\n",
        "                k = n_features - round(math.sqrt(n_features)) + 1\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid subspace_size: {self.subspace_size}.\")\n",
        "            if k < 0:\n",
        "                k = n_features + k\n",
        "            if k != 0 and k < n_features:\n",
        "                if n_features <= 20 or k < 2:\n",
        "                    if k == 1 and n_features > 2:\n",
        "                        k = 2\n",
        "                    self._subspaces = []\n",
        "                    for i, combination in enumerate(\n",
        "                        itertools.cycle(itertools.combinations(features, k))\n",
        "                    ):\n",
        "                        if i == self.n_models:\n",
        "                            break\n",
        "                        self._subspaces.append(list(combination))\n",
        "                else:\n",
        "                    self._subspaces = [\n",
        "                        random_subspace(all_features=features, k=k, rng=self._rng)\n",
        "                        for _ in range(self.n_models)\n",
        "                    ]\n",
        "            else:\n",
        "                # When k is not less than the number of features, switch to resampling.\n",
        "                self.training_method = self._TRAIN_RESAMPLING\n",
        "                self._subspaces = [None] * self.n_models\n",
        "        else:\n",
        "            self._subspaces = [None] * self.n_models\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = []\n",
        "        self._n_samples_seen = 0\n",
        "        self._rng = random.Random(self.seed)\n",
        "\n",
        "class BaseSRPEstimator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        idx_original: int,\n",
        "        model: base.Estimator,\n",
        "        metric: Accuracy,\n",
        "        created_on: int,\n",
        "        drift_detector: base.DriftDetector,\n",
        "        warning_detector: base.DriftDetector,\n",
        "        is_background_learner,\n",
        "        rng: random.Random,\n",
        "        features=None,\n",
        "    ):\n",
        "        self.idx_original = idx_original\n",
        "        self.created_on = created_on\n",
        "        self.model = model.clone()\n",
        "        self.metric = metric.clone()\n",
        "        self.features = features\n",
        "        if drift_detector is not None:\n",
        "            self.disable_drift_detector = False\n",
        "            self.drift_detector = drift_detector.clone()\n",
        "        else:\n",
        "            self.disable_drift_detector = True\n",
        "            self.drift_detector = None\n",
        "        if warning_detector is not None:\n",
        "            self.disable_background_learner = False\n",
        "            self.warning_detector = warning_detector.clone()\n",
        "        else:\n",
        "            self.disable_background_learner = True\n",
        "            self.warning_detector = None\n",
        "        self.is_background_learner = is_background_learner\n",
        "        self.n_drifts_detected = 0\n",
        "        self.n_warnings_detected = 0\n",
        "        self.rng = rng\n",
        "        self._background_learner = None\n",
        "\n",
        "###############################################################################\n",
        "# Base Learner for Classification with Weighting (including reset)\n",
        "###############################################################################\n",
        "\n",
        "class BaseSRPClassifier(BaseSRPEstimator):\n",
        "    def __init__(\n",
        "        self,\n",
        "        idx_original: int,\n",
        "        model: base.Classifier,\n",
        "        metric: Accuracy,\n",
        "        created_on: int,\n",
        "        drift_detector: base.DriftDetector,\n",
        "        warning_detector: base.DriftDetector,\n",
        "        is_background_learner,\n",
        "        rng: random.Random,\n",
        "        features=None,\n",
        "    ):\n",
        "        super().__init__(idx_original, model, metric, created_on, drift_detector, warning_detector, is_background_learner, rng, features)\n",
        "        self.weight = 1.0  # initialize the learner's weight\n",
        "\n",
        "    def reset(self, all_features: list, n_samples_seen: int):\n",
        "        # Optionally update the feature subspace\n",
        "        if self.features is not None:\n",
        "            self.features = random_subspace(all_features, len(self.features), self.rng)\n",
        "        self.model = self.model.clone()\n",
        "        self.metric = self.metric.clone()\n",
        "        self.created_on = n_samples_seen\n",
        "        if self.drift_detector is not None:\n",
        "            self.drift_detector = self.drift_detector.clone()\n",
        "        if self.warning_detector is not None:\n",
        "            self.warning_detector = self.warning_detector.clone()\n",
        "        self.weight = 1.0\n",
        "\n",
        "    def learn_one(self, x: dict, y: base.typing.ClfTarget, *, w: int, n_samples_seen: int, **kwargs):\n",
        "        if self.features is not None:\n",
        "            x_subset = {k: x[k] for k in self.features if k in x}\n",
        "        else:\n",
        "            x_subset = x\n",
        "        for _ in range(int(w)):\n",
        "            self.model.learn_one(x=x_subset, y=y, **kwargs)\n",
        "        if self._background_learner:\n",
        "            self._background_learner.learn_one(x=x, y=y, w=w, n_samples_seen=n_samples_seen)\n",
        "        if not self.disable_drift_detector and not self.is_background_learner:\n",
        "            y_pred = self.model.predict_one(x_subset)\n",
        "            correctly_classifies = (y_pred == y)\n",
        "            # Update learner's weight\n",
        "            if correctly_classifies:\n",
        "                self.weight *= 0.9\n",
        "            else:\n",
        "                self.weight *= 1.1\n",
        "            self.warning_detector.update(int(not correctly_classifies))\n",
        "            if self.warning_detector.drift_detected:\n",
        "                all_features = list(x.keys())\n",
        "                self.n_warnings_detected += 1\n",
        "            self.drift_detector.update(int(not correctly_classifies))\n",
        "            if self.drift_detector.drift_detected:\n",
        "                all_features = list(x.keys())\n",
        "                self.n_drifts_detected += 1\n",
        "                self.reset(all_features=all_features, n_samples_seen=n_samples_seen)\n",
        "\n",
        "    def predict_proba_one(self, x, **kwargs):\n",
        "        if self.features is not None:\n",
        "            x_subset = {k: x[k] for k in self.features if k in x}\n",
        "        else:\n",
        "            x_subset = x\n",
        "        return self.model.predict_proba_one(x_subset, **kwargs)\n",
        "\n",
        "    def predict_one(self, x: dict, **kwargs) -> base.typing.ClfTarget:\n",
        "        y_pred = self.predict_proba_one(x, **kwargs)\n",
        "        if y_pred:\n",
        "            return max(y_pred, key=y_pred.get)\n",
        "        return None\n",
        "\n",
        "###############################################################################\n",
        "# Standard SRPClassifier (for reference)\n",
        "###############################################################################\n",
        "\n",
        "class SRPClassifier(BaseSRPEnsemble, base.Classifier):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: base.Estimator | None = None,\n",
        "        n_models: int = 10,\n",
        "        subspace_size: int | float | str = 0.6,\n",
        "        training_method: str = \"patches\",\n",
        "        lam: int = 6,\n",
        "        drift_detector: base.DriftDetector | None = None,\n",
        "        warning_detector: base.DriftDetector | None = None,\n",
        "        disable_detector: str = \"off\",\n",
        "        disable_weighted_vote: bool = False,\n",
        "        seed: int | None = None,\n",
        "        metric: Accuracy | None = None,\n",
        "    ):\n",
        "        if model is None:\n",
        "            model = HoeffdingTreeClassifier(grace_period=50, delta=0.01)\n",
        "        if drift_detector is None:\n",
        "            drift_detector = ADWIN(delta=1e-5)\n",
        "        if warning_detector is None:\n",
        "            warning_detector = ADWIN(delta=1e-4)\n",
        "        if metric is None:\n",
        "            metric = Accuracy()\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            n_models=n_models,\n",
        "            subspace_size=subspace_size,\n",
        "            training_method=training_method,\n",
        "            lam=lam,\n",
        "            drift_detector=drift_detector,\n",
        "            warning_detector=warning_detector,\n",
        "            disable_detector=disable_detector,\n",
        "            disable_weighted_vote=disable_weighted_vote,\n",
        "            seed=seed,\n",
        "            metric=metric,\n",
        "        )\n",
        "        self._base_learner_class = BaseSRPClassifier\n",
        "\n",
        "    def predict_proba_one(self, x, **kwargs):\n",
        "        y_pred = collections.Counter()\n",
        "        if not self:\n",
        "            self._init_ensemble(features=list(x.keys()))\n",
        "            return y_pred\n",
        "        for model in self:\n",
        "            y_proba_temp = model.predict_proba_one(x, **kwargs)\n",
        "            # Here we use the individual learner's weight\n",
        "            weight = model.weight\n",
        "            y_proba_temp = {k: val * weight for k, val in y_proba_temp.items()}\n",
        "            y_pred.update(y_proba_temp)\n",
        "        total = sum(y_pred.values())\n",
        "        if total > 0:\n",
        "            return {label: proba / total for label, proba in y_pred.items()}\n",
        "        return y_pred\n",
        "\n",
        "    def predict_one(self, x, **kwargs):\n",
        "        y_pred = self.predict_proba_one(x, **kwargs)\n",
        "        if y_pred:\n",
        "            return max(y_pred, key=y_pred.get)\n",
        "        return None\n",
        "\n",
        "###############################################################################\n",
        "# Dynamic SRPClassifier: Adaptive Ensemble Size with Per-Tree Weighting\n",
        "###############################################################################\n",
        "\n",
        "class DynamicSRPClassifier(SRPClassifier):\n",
        "    @property\n",
        "    def _min_number_of_models(self):\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def _wrapped_model(self):\n",
        "        return self.model\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: base.Estimator | None = None,\n",
        "        n_models: int = 10,\n",
        "        max_models: int = 100,\n",
        "        subspace_size: int | float | str = 0.6,\n",
        "        training_method: str = \"patches\",\n",
        "        lam: int = 6,\n",
        "        drift_detector: base.DriftDetector | None = None,\n",
        "        warning_detector: base.DriftDetector | None = None,\n",
        "        disable_detector: str = \"off\",\n",
        "        disable_weighted_vote: bool = False,\n",
        "        seed: int | None = None,\n",
        "        metric: Accuracy | None = None,\n",
        "        window_size: int = 100,\n",
        "        performance_threshold: float = 0.8,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            n_models=n_models,\n",
        "            subspace_size=subspace_size,\n",
        "            training_method=training_method,\n",
        "            lam=lam,\n",
        "            drift_detector=drift_detector,\n",
        "            warning_detector=warning_detector,\n",
        "            disable_detector=disable_detector,\n",
        "            disable_weighted_vote=disable_weighted_vote,\n",
        "            seed=seed,\n",
        "            metric=metric,\n",
        "        )\n",
        "        self._max_models = max_models\n",
        "        self._window_size = window_size\n",
        "        self._performance_threshold = performance_threshold\n",
        "        self._sliding_window = collections.deque(maxlen=window_size)\n",
        "        # Initialize per-learner performance metrics\n",
        "        self.tree_accuracies = [1.0] * n_models\n",
        "        self.correct_predictions = [0] * n_models\n",
        "        self.total_predictions = [0] * n_models\n",
        "        self.ensemble_weights = [1.0 / n_models] * n_models\n",
        "\n",
        "    def learn_one(self, x: dict, y: base.typing.ClfTarget, **kwargs):\n",
        "        self._n_samples_seen += 1\n",
        "        if not self:\n",
        "            self._init_ensemble(features=list(x.keys()))\n",
        "        # Train each base learner with online bagging\n",
        "        for model in self:\n",
        "            y_pred = model.predict_one(x)\n",
        "            if y_pred is not None:\n",
        "                model.metric.update(y_true=y, y_pred=y_pred)\n",
        "            if self.training_method == self._TRAIN_RANDOM_SUBSPACES:\n",
        "                k = 1\n",
        "            else:\n",
        "                k = poisson(rate=self.lam, rng=self._rng)\n",
        "                if k == 0:\n",
        "                    continue\n",
        "            model.learn_one(x=x, y=y, w=k, n_samples_seen=self._n_samples_seen, **kwargs)\n",
        "        # Update per-learner performance metrics:\n",
        "        for i, learner in enumerate(self):\n",
        "            pred = learner.predict_one(x)\n",
        "            if pred == y:\n",
        "                self.tree_accuracies[i] *= 0.9\n",
        "                self.correct_predictions[i] += 1\n",
        "            else:\n",
        "                self.tree_accuracies[i] *= 1.1\n",
        "            self.total_predictions[i] += 1\n",
        "        # Update ensemble weights:\n",
        "        self.ensemble_weights = [1 / (1 + acc) for acc in self.tree_accuracies]\n",
        "        total_weight = sum(self.ensemble_weights)\n",
        "        self.ensemble_weights = [w / total_weight for w in self.ensemble_weights]\n",
        "        # Update sliding window for ensemble-level performance:\n",
        "        ensemble_pred = self.predict_one(x)\n",
        "        correct = 1 if ensemble_pred == y else 0\n",
        "        self._sliding_window.append(correct)\n",
        "        if len(self._sliding_window) == self._window_size:\n",
        "            window_accuracy = sum(self._sliding_window) / self._window_size\n",
        "            if window_accuracy < self._performance_threshold:\n",
        "                features = list(x.keys())\n",
        "                if len(self) < self._max_models:\n",
        "                    self._add_learner(features)\n",
        "                    self.tree_accuracies.append(1.0)\n",
        "                    self.correct_predictions.append(0)\n",
        "                    self.total_predictions.append(0)\n",
        "                    self.ensemble_weights.append(1.0 / (len(self)))\n",
        "                else:\n",
        "                    worst_index = self._remove_worst_learner()\n",
        "                    self._add_learner(features)\n",
        "                    # Remove corresponding metrics of removed learner:\n",
        "                    del self.tree_accuracies[worst_index]\n",
        "                    del self.correct_predictions[worst_index]\n",
        "                    del self.total_predictions[worst_index]\n",
        "                    del self.ensemble_weights[worst_index]\n",
        "                    # Append default values for the new learner:\n",
        "                    self.tree_accuracies.append(1.0)\n",
        "                    self.correct_predictions.append(0)\n",
        "                    self.total_predictions.append(0)\n",
        "                    self.ensemble_weights.append(1.0 / (len(self)))\n",
        "                self._sliding_window.clear()\n",
        "\n",
        "    def _generate_subspace_single(self, features: list):\n",
        "        n_features = len(features)\n",
        "        if self.training_method != self._TRAIN_RESAMPLING:\n",
        "            if isinstance(self.subspace_size, float) and 0.0 < self.subspace_size <= 1:\n",
        "                k = self.subspace_size\n",
        "                percent = (1.0 + k)\n",
        "                k = round(n_features * percent)\n",
        "                if k < 2:\n",
        "                    k = round(n_features * percent) + 1\n",
        "            elif isinstance(self.subspace_size, int) and self.subspace_size > 2:\n",
        "                k = self.subspace_size\n",
        "            elif self.subspace_size == self._FEATURES_SQRT:\n",
        "                k = round(math.sqrt(n_features)) + 1\n",
        "            elif self.subspace_size == self._FEATURES_SQRT_INV:\n",
        "                k = n_features - round(math.sqrt(n_features)) + 1\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid subspace_size: {self.subspace_size}.\")\n",
        "            if k < 0:\n",
        "                k = n_features + k\n",
        "            if k != 0 and k < n_features:\n",
        "                return random_subspace(all_features=features, k=k, rng=self._rng)\n",
        "            else:\n",
        "                self.training_method = self._TRAIN_RESAMPLING\n",
        "                return None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def _add_learner(self, features: list):\n",
        "        subspace = self._generate_subspace_single(features)\n",
        "        new_learner = self._base_learner_class(\n",
        "            idx_original=len(self),\n",
        "            model=self.model,\n",
        "            metric=self.metric.clone(),\n",
        "            created_on=self._n_samples_seen,\n",
        "            drift_detector=self.drift_detector,\n",
        "            warning_detector=self.warning_detector,\n",
        "            is_background_learner=False,\n",
        "            rng=self._rng,\n",
        "            features=subspace,\n",
        "        )\n",
        "        new_learner.weight = 1.0\n",
        "        self.append(new_learner)\n",
        "\n",
        "    def _remove_worst_learner(self):\n",
        "        worst_index = None\n",
        "        worst_weight = float('inf')\n",
        "        for i, _ in enumerate(self):\n",
        "            if self.ensemble_weights[i] < worst_weight:\n",
        "                worst_weight = self.ensemble_weights[i]\n",
        "                worst_index = i\n",
        "        if worst_index is not None:\n",
        "            del self[worst_index]\n",
        "            return worst_index\n",
        "        return None\n",
        "\n",
        "    def predict_proba_one(self, x, **kwargs):\n",
        "        y_pred = collections.Counter()\n",
        "        if not self:\n",
        "            self._init_ensemble(features=list(x.keys()))\n",
        "            return y_pred\n",
        "        for i, learner in enumerate(self):\n",
        "            learner_proba = learner.predict_proba_one(x, **kwargs)\n",
        "            weight = self.ensemble_weights[i]\n",
        "            learner_proba = {k: val * weight for k, val in learner_proba.items()}\n",
        "            y_pred.update(learner_proba)\n",
        "        total = sum(y_pred.values())\n",
        "        if total > 0:\n",
        "            return {label: proba / total for label, proba in y_pred.items()}\n",
        "        return y_pred\n",
        "\n",
        "    def predict_one(self, x, **kwargs):\n",
        "        y_pred = self.predict_proba_one(x, **kwargs)\n",
        "        if y_pred:\n",
        "            return max(y_pred, key=y_pred.get)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "PXmMSg8xmcKt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from river import ensemble, evaluate, metrics, datasets, tree\n",
        "\n",
        "# Create a synthetic concept drift stream\n",
        "dataset = datasets.synth.ConceptDriftStream(\n",
        "    seed=42,\n",
        "    position=500,\n",
        "    width=50\n",
        ").take(10000)\n",
        "\n",
        "# Define a base model (Hoeffding Tree)\n",
        "base_model = tree.HoeffdingTreeClassifier(\n",
        "    grace_period=50, delta=0.01,\n",
        "    nominal_attributes=['age', 'car', 'zipcode']\n",
        ")\n",
        "\n",
        "# --- Original SRPClassifier ---\n",
        "original_model = ensemble.SRPClassifier(\n",
        "    model=base_model,\n",
        "    n_models=10,  # e.g., 3 base learners\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "metric = metrics.Accuracy()\n",
        "\n",
        "result_original = evaluate.progressive_val_score(dataset, original_model, metric)\n",
        "print(\"Original SRPClassifier Accuracy:\", result_original)\n",
        "\n",
        "# Reinitialize the stream for a fair comparison\n",
        "dataset = datasets.synth.ConceptDriftStream(\n",
        "    seed=42,\n",
        "    position=500,\n",
        "    width=50\n",
        ").take(10000)\n",
        "\n",
        "# --- Dynamic SRPClassifier ---\n",
        "dynamic_model = DynamicSRPClassifier(\n",
        "    model=base_model,\n",
        "    n_models=10,        # starting with 10 learners\n",
        "    max_models=100,     # ensemble will grow up to 100 learners\n",
        "    seed=42,\n",
        "    window_size=100,           # sliding window size for performance monitoring\n",
        "    performance_threshold=0.8  # if accuracy over window falls below 80%, add a learner\n",
        ")\n",
        "\n",
        "result_dynamic = evaluate.progressive_val_score(dataset, dynamic_model, metric)\n",
        "print(\"Dynamic SRPClassifier Accuracy:\", result_dynamic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEYTkT9AmfYV",
        "outputId": "5414781e-f220-42eb-f345-e0e18c11a871"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original SRPClassifier Accuracy: Accuracy: 68.68%\n",
            "Dynamic SRPClassifier Accuracy: Accuracy: 75.58%\n"
          ]
        }
      ]
    }
  ]
}